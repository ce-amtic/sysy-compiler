.section .rodata
__fmt_string0:	.string "%d\n"

.section .data

.section .bss

.section .text

	.globl	foo
	.type	foo, @function
foo:
	pushq	%rbp
	movq	%rsp, %rbp
	subq	$272, %rsp                       # fixed frame size
	movl	$0, -64(%rbp)
	movl	$1, -60(%rbp)
	movl	$2, -56(%rbp)
	movl	$3, -52(%rbp)
	movl	$0, -48(%rbp)
	movl	$1, -44(%rbp)
	movl	$2, -40(%rbp)
	movl	$3, -36(%rbp)
	movl	$0, -32(%rbp)
	movl	$1, -28(%rbp)
	movl	$2, -24(%rbp)
	movl	$3, -20(%rbp)
	movl	$0, -16(%rbp)
	movl	$1, -12(%rbp)
	movl	$2, -8(%rbp)
	movl	$3, -4(%rbp)
	movl	$3, -68(%rbp)
	movl	$7, -72(%rbp)
	movl	$5, -76(%rbp)
	movl	$6, -80(%rbp)
	movl	$1, -84(%rbp)
	movl	$0, -88(%rbp)
	movl	$3, -92(%rbp)
	movl	$5, -96(%rbp)
	movl	$4, -100(%rbp)
	movl	$2, -104(%rbp)
	movl	$7, -108(%rbp)
	movl	$9, -112(%rbp)
	movl	$8, -116(%rbp)
	movl	$1, -120(%rbp)
	movl	$4, -124(%rbp)
	movl	$6, -128(%rbp)
	movl	-68(%rbp), %r8d
	movl	%r8d, -132(%rbp)
	movl	-72(%rbp), %r8d
	movl	%r8d, -136(%rbp)
	movl	-132(%rbp), %r8d
	movl	-136(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -140(%rbp)
	movl	-76(%rbp), %r8d
	movl	%r8d, -144(%rbp)
	movl	-140(%rbp), %r8d
	movl	-144(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -148(%rbp)
	movl	-80(%rbp), %r8d
	movl	%r8d, -152(%rbp)
	movl	-148(%rbp), %r8d
	movl	-152(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -156(%rbp)
	movl	-84(%rbp), %r8d
	movl	%r8d, -160(%rbp)
	movl	-156(%rbp), %r8d
	movl	-160(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -164(%rbp)
	movl	-88(%rbp), %r8d
	movl	%r8d, -168(%rbp)
	movl	-164(%rbp), %r8d
	movl	-168(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -172(%rbp)
	movl	-92(%rbp), %r8d
	movl	%r8d, -176(%rbp)
	movl	-172(%rbp), %r8d
	movl	-176(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -180(%rbp)
	movl	-96(%rbp), %r8d
	movl	%r8d, -184(%rbp)
	movl	-180(%rbp), %r8d
	movl	-184(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -188(%rbp)
	movl	-100(%rbp), %r8d
	movl	%r8d, -192(%rbp)
	movl	-104(%rbp), %r8d
	movl	%r8d, -196(%rbp)
	movl	-192(%rbp), %r8d
	movl	-196(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -200(%rbp)
	movl	-108(%rbp), %r8d
	movl	%r8d, -204(%rbp)
	movl	-200(%rbp), %r8d
	movl	-204(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -208(%rbp)
	movl	-112(%rbp), %r8d
	movl	%r8d, -212(%rbp)
	movl	-208(%rbp), %r8d
	movl	-212(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -216(%rbp)
	movl	-116(%rbp), %r8d
	movl	%r8d, -220(%rbp)
	movl	-216(%rbp), %r8d
	movl	-220(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -224(%rbp)
	movl	-120(%rbp), %r8d
	movl	%r8d, -228(%rbp)
	movl	-224(%rbp), %r8d
	movl	-228(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -232(%rbp)
	movl	-124(%rbp), %r8d
	movl	%r8d, -236(%rbp)
	movl	-232(%rbp), %r8d
	movl	-236(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -240(%rbp)
	movl	-128(%rbp), %r8d
	movl	%r8d, -244(%rbp)
	movl	-240(%rbp), %r8d
	movl	-244(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -248(%rbp)
	movl	-188(%rbp), %r8d
	movl	%r8d, -252(%rbp)
	movl	-248(%rbp), %r8d
	movl	%r8d, -256(%rbp)
	movl	-252(%rbp), %r8d
	movl	-256(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -260(%rbp)
	movl	-68(%rbp), %r8d
	movl	%r8d, -264(%rbp)
	movl	$0, %ecx
	imull	$16, %ecx
	movl	-264(%rbp), %r8d
	addl	%r8d, %ecx
	movslq	%ecx, %rcx
	movl	-64(%rbp, %rcx, 4), %eax
	movl	%eax, -268(%rbp)
	movl	-260(%rbp), %r8d
	movl	-268(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -272(%rbp)
	movl	-272(%rbp), %eax
	leave
	ret

	.globl	main
	.type	main, @function
main:
	pushq	%rbp
	movq	%rsp, %rbp
	subq	$368, %rsp                       # fixed frame size
	movl	$3, -4(%rbp)
	movl	$7, -8(%rbp)
	movl	$5, -12(%rbp)
	movl	$6, -16(%rbp)
	movl	$1, -20(%rbp)
	movl	$0, -24(%rbp)
	movl	$3, -28(%rbp)
	movl	$5, -32(%rbp)
	movl	$4, -36(%rbp)
	movl	$2, -40(%rbp)
	movl	$7, -44(%rbp)
	movl	$9, -48(%rbp)
	movl	$8, -52(%rbp)
	movl	$1, -56(%rbp)
	movl	$4, -60(%rbp)
	movl	$6, -64(%rbp)
	movl	-4(%rbp), %r8d
	movl	%r8d, -68(%rbp)
	movl	-8(%rbp), %r8d
	movl	%r8d, -72(%rbp)
	movl	-68(%rbp), %r8d
	movl	-72(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -76(%rbp)
	movl	-12(%rbp), %r8d
	movl	%r8d, -80(%rbp)
	movl	-76(%rbp), %r8d
	movl	-80(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -84(%rbp)
	movl	-16(%rbp), %r8d
	movl	%r8d, -88(%rbp)
	movl	-84(%rbp), %r8d
	movl	-88(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -92(%rbp)
	movl	-20(%rbp), %r8d
	movl	%r8d, -96(%rbp)
	movl	-92(%rbp), %r8d
	movl	-96(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -100(%rbp)
	movl	-24(%rbp), %r8d
	movl	%r8d, -104(%rbp)
	movl	-100(%rbp), %r8d
	movl	-104(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -108(%rbp)
	movl	-28(%rbp), %r8d
	movl	%r8d, -112(%rbp)
	movl	-108(%rbp), %r8d
	movl	-112(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -116(%rbp)
	movl	-32(%rbp), %r8d
	movl	%r8d, -120(%rbp)
	movl	-116(%rbp), %r8d
	movl	-120(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -124(%rbp)
	movl	-36(%rbp), %r8d
	movl	%r8d, -128(%rbp)
	movl	-40(%rbp), %r8d
	movl	%r8d, -132(%rbp)
	movl	-128(%rbp), %r8d
	movl	-132(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -136(%rbp)
	movl	-44(%rbp), %r8d
	movl	%r8d, -140(%rbp)
	movl	-136(%rbp), %r8d
	movl	-140(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -144(%rbp)
	movl	-48(%rbp), %r8d
	movl	%r8d, -148(%rbp)
	movl	-144(%rbp), %r8d
	movl	-148(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -152(%rbp)
	movl	-52(%rbp), %r8d
	movl	%r8d, -156(%rbp)
	movl	-152(%rbp), %r8d
	movl	-156(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -160(%rbp)
	movl	-56(%rbp), %r8d
	movl	%r8d, -164(%rbp)
	movl	-160(%rbp), %r8d
	movl	-164(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -168(%rbp)
	movl	-60(%rbp), %r8d
	movl	%r8d, -172(%rbp)
	movl	-168(%rbp), %r8d
	movl	-172(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -176(%rbp)
	movl	-64(%rbp), %r8d
	movl	%r8d, -180(%rbp)
	movl	-176(%rbp), %r8d
	movl	-180(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -184(%rbp)
	movl	-124(%rbp), %r8d
	movl	%r8d, -188(%rbp)
	call	foo
	movl	%eax, -192(%rbp)
	movl	-188(%rbp), %r8d
	movl	-192(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -196(%rbp)
	movl	-196(%rbp), %eax
	movl	%eax, -124(%rbp)                 # assign int
	movl	$4, -200(%rbp)
	movl	$7, -204(%rbp)
	movl	$2, -208(%rbp)
	movl	$5, -212(%rbp)
	movl	$8, -216(%rbp)
	movl	$0, -220(%rbp)
	movl	$6, -224(%rbp)
	movl	$3, -228(%rbp)
	movl	-184(%rbp), %r8d
	movl	%r8d, -232(%rbp)
	call	foo
	movl	%eax, -236(%rbp)
	movl	-232(%rbp), %r8d
	movl	-236(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -240(%rbp)
	movl	-240(%rbp), %eax
	movl	%eax, -184(%rbp)                 # assign int
	movl	-36(%rbp), %r8d
	movl	%r8d, -244(%rbp)
	movl	-244(%rbp), %eax
	movl	%eax, -4(%rbp)                   # assign int
	movl	-40(%rbp), %r8d
	movl	%r8d, -248(%rbp)
	movl	-248(%rbp), %eax
	movl	%eax, -8(%rbp)                   # assign int
	movl	-44(%rbp), %r8d
	movl	%r8d, -252(%rbp)
	movl	-252(%rbp), %eax
	movl	%eax, -12(%rbp)                  # assign int
	movl	-48(%rbp), %r8d
	movl	%r8d, -256(%rbp)
	movl	-256(%rbp), %eax
	movl	%eax, -16(%rbp)                  # assign int
	movl	-52(%rbp), %r8d
	movl	%r8d, -260(%rbp)
	movl	-260(%rbp), %eax
	movl	%eax, -20(%rbp)                  # assign int
	movl	-56(%rbp), %r8d
	movl	%r8d, -264(%rbp)
	movl	-264(%rbp), %eax
	movl	%eax, -24(%rbp)                  # assign int
	movl	-60(%rbp), %r8d
	movl	%r8d, -268(%rbp)
	movl	-268(%rbp), %eax
	movl	%eax, -28(%rbp)                  # assign int
	movl	-64(%rbp), %r8d
	movl	%r8d, -272(%rbp)
	movl	-272(%rbp), %eax
	movl	%eax, -32(%rbp)                  # assign int
	movl	-200(%rbp), %r8d
	movl	%r8d, -276(%rbp)
	movl	-204(%rbp), %r8d
	movl	%r8d, -280(%rbp)
	movl	-276(%rbp), %r8d
	movl	-280(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -284(%rbp)
	movl	-208(%rbp), %r8d
	movl	%r8d, -288(%rbp)
	movl	-284(%rbp), %r8d
	movl	-288(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -292(%rbp)
	movl	-212(%rbp), %r8d
	movl	%r8d, -296(%rbp)
	movl	-292(%rbp), %r8d
	movl	-296(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -300(%rbp)
	movl	-216(%rbp), %r8d
	movl	%r8d, -304(%rbp)
	movl	-300(%rbp), %r8d
	movl	-304(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -308(%rbp)
	movl	-220(%rbp), %r8d
	movl	%r8d, -312(%rbp)
	movl	-308(%rbp), %r8d
	movl	-312(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -316(%rbp)
	movl	-224(%rbp), %r8d
	movl	%r8d, -320(%rbp)
	movl	-316(%rbp), %r8d
	movl	-320(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -324(%rbp)
	movl	-228(%rbp), %r8d
	movl	%r8d, -328(%rbp)
	movl	-324(%rbp), %r8d
	movl	-328(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -332(%rbp)
	movl	-124(%rbp), %r8d
	movl	%r8d, -336(%rbp)
	movl	-184(%rbp), %r8d
	movl	%r8d, -340(%rbp)
	movl	-336(%rbp), %r8d
	movl	-340(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -344(%rbp)
	movl	-332(%rbp), %r8d
	movl	%r8d, -348(%rbp)
	movl	-344(%rbp), %r8d
	movl	-348(%rbp), %r9d
	addl	%r9d, %r8d
	movl	%r8d, -352(%rbp)
	movl	-352(%rbp), %r8d
	movl	%r8d, -356(%rbp)
	leaq	__fmt_string0(%rip), %rdi        # param 0
	movl	-356(%rbp), %r8d
	movsxd	%r8d, %r8
	movq	%r8, %rsi                        # param 1
	call	printf
	movl	$0, %eax
	leave
	ret
